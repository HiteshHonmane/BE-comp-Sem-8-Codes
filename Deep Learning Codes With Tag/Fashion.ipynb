{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "YjtG_buS90-4"
      },
      "outputs": [],
      "source": [
        "# Import libraries for array manipulations, data visualization and data processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Import libraries to interact with Google Colab and Google Drive\n",
        "from google.colab import drive\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access dataset stored there\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check the current directory's content\n",
        "print(os.listdir('.'))\n"
      ],
      "metadata": {
        "id": "LhlOKT8Yo_GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the train and test data from csv files stored in Google Drive\n",
        "fashion_train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fashion-mnist_train.csv')\n",
        "fashion_test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fashion-mnist_test.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "N1Qlplgj99rd"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the train and test data\n",
        "fashion_train_df.head()\n",
        "fashion_train_df.tail()\n",
        "print(\"Train data shape:\", fashion_train_df.shape)\n",
        "print(\"Test data shape:\", fashion_test_df.shape)\n"
      ],
      "metadata": {
        "id": "5FuSqLEro0B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the train and test data\n",
        "fashion_train_df.head()\n",
        "fashion_train_df.tail()\n",
        "print(\"Train data shape:\", fashion_train_df.shape)\n",
        "print(\"Test data shape:\", fashion_test_df.shape)\n"
      ],
      "metadata": {
        "id": "OiEZjrj9l9eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert DataFrame to NumPy array for further processing with float32 data type\n",
        "training = np.array(fashion_train_df, dtype='float32')\n",
        "testing = np.array(fashion_test_df, dtype='float32')\n"
      ],
      "metadata": {
        "id": "9A82vhj4uwGE"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualize some samples of the training data\n",
        "import random\n",
        "i = random.randint(0, 60001)\n",
        "plt.imshow(training[i, 1:].reshape(28, 28))  # Draw the image\n",
        "label = training[i, 1]  # Extract the label\n",
        "print(\"Label:\", label)\n"
      ],
      "metadata": {
        "id": "96QHbOzauylF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data for model\n",
        "# Normalize pixel values by dividing with 255, separate the labels from the images\n",
        "\n",
        "X_train = training[:, 1:] / 255\n",
        "y_train = training[:, 0]\n",
        "X_test = testing[:, 1:] / 255\n",
        "y_test = testing[:, 0]\n"
      ],
      "metadata": {
        "id": "EVwWNnZHu0zr"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the train data into train and validation datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n"
      ],
      "metadata": {
        "id": "nTOTMkz2u3Q1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data to fit the model\n",
        "X_train = X_train.reshape(X_train.shape[0], *(28, 28, 1))\n",
        "X_test = X_test.reshape(X_test.shape[0], *(28, 28, 1))\n",
        "X_validate = X_validate.reshape(X_validate.shape[0], *(28, 28, 1))\n"
      ],
      "metadata": {
        "id": "x6JfE07jwMdc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries for model creation and compilation\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create the CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(32, 3, 3, input_shape=(28, 28, 1), activation='relu'))  # Convolutional layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))  # MaxPooling layer\n",
        "cnn_model.add(Flatten())  # Flatten layer\n",
        "cnn_model.add(Dense(32, activation='relu'))  # Fully connected layer\n",
        "cnn_model.add(Dense(10, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model using Adam optimizer and sparse_categorical_crossentropy loss function\n",
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001))\n"
      ],
      "metadata": {
        "id": "AggelkTKwQjz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "# Set the number of epochs and batch size\n",
        "\n",
        "epochs = 200\n",
        "cnn_model.fit(X_train, y_train, batch_size=512, epochs=epochs, verbose=1, validation_data=(X_validate, y_validate))\n",
        "\n"
      ],
      "metadata": {
        "id": "K55xSiU5wWyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model on the test data\n",
        "evaluation = cnn_model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy: {:.3f}'.format(evaluation))\n"
      ],
      "metadata": {
        "id": "k0fpIbdYwZDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the classes of the test data\n",
        "predicted_classes = np.argmax(cnn_model.predict(X_test), axis=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_p2L5Fkwet0",
        "outputId": "c564cf50-0dcc-4861-ef1f-bd2225310319"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display images from the test dataset with their predicted and true labels\n",
        "L = 5\n",
        "W = 5\n",
        "fig, axes = plt.subplots(L, W, figsize=(12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L * W):\n",
        "    axes[i].imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
        "    axes[i].set_title('Prediction Class: {0} \\nTrue Class: {1}'.format(predicted_classes[i], y_test[i]))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5)\n"
      ],
      "metadata": {
        "id": "Zrt7cf6ewjp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library for classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print the classification report\n",
        "classes = 10\n",
        "targets = [\"Class {}\".format(i) for i in range(classes)]\n",
        "print(classification_report(y_test, predicted_classes, target_names=targets))\n"
      ],
      "metadata": {
        "id": "PxdkHwLdwme0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}